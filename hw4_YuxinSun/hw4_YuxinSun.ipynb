{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Report\n",
    "## Yuxin Sun\n",
    "\n",
    "------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Creating Your Own Image Classification Dataset\n",
    "\n",
    "In my DataSet, I sample 2000 unique images for each class. The training set and testing set are stored together in one DataSet, \n",
    "and I use `SubsetRandomSampler` in `torch.utils.data.sampler` to make sure there is no overlap between two sets.\n",
    "\n",
    "\n",
    "\n",
    "Figure 1: resized image from COCO\n",
    "\n",
    "![5 class x3](./5_class.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Image Classification using CNNs â€“ Training and Validation\n",
    "\n",
    "### parameters\n",
    "In the following code, xxxx = 32\\*14\\*14:\n",
    "\n",
    "Our input image is $64\\times64$, and it changes as $64\\to62\\to31\\to29\\to14$, so the final image should have size $14\\times14$. \n",
    "The final `Conv2d` has 32 channel, so xxxx=32\\*14\\*14.\n",
    "\n",
    "xx = 5 because it is the number of classes we have.\n",
    "```python\n",
    "class HW4Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HW4Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(xxxx, 64)\n",
    "        self.fc2 = nn.Linear(64, xx)\n",
    "```\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "Confusion matrices for 3 nets:\n",
    "```python\n",
    "tensor([[   0.,   37.,  175.,  216., 1072.],\n",
    "        [   0., 1094.,  236.,   44.,  126.],\n",
    "        [   0.,  176., 1054.,   82.,  188.],\n",
    "        [   0.,  110.,  243.,  563.,  584.],\n",
    "        [   0.,  168.,  376.,  341.,  615.]])\n",
    "\n",
    "tensor([[   0.,   12.,   85.,  133., 1270.],\n",
    "        [   0.,  902.,  264.,   64.,  270.],\n",
    "        [   0.,  100.,  963.,   70.,  367.],\n",
    "        [   0.,   55.,  154.,  492.,  799.],\n",
    "        [   0.,  102.,  242.,  275.,  881.]])\n",
    "\n",
    "tensor([[   0.,   24.,   75.,  158., 1243.],\n",
    "        [   0., 1100.,  184.,   61.,  155.],\n",
    "        [   0.,  184.,  832.,  141.,  343.],\n",
    "        [   0.,  177.,  178.,  434.,  711.],\n",
    "        [   0.,  221.,  276.,  331.,  672.]])\n",
    "```\n",
    "\n",
    "### Normalized Confusion matrices plot\n",
    "\n",
    "Figure 2: \n",
    "\n",
    "![cf_matrix](./confusion1.jpg)\n",
    "\n",
    "Figure 3: \n",
    "\n",
    "![cf_matrix](./confusion2.jpg)\n",
    "\n",
    "Figure 4: \n",
    "\n",
    "![cf_matrix](./confusion3.jpg)\n",
    "\n",
    "Figure 5: Training Loss vs #Batch/100\n",
    "\n",
    "![loss](./output1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### 1. Does adding padding to the convolutional layers make a difference in classification performance?\n",
    "A: Yes, the confusion matrix looks a little bit different. But adding padding doesn't make it performs better.\n",
    "\n",
    "### 2. As you may have known, naively chaining a large number of layers can result in difficulties in training. This phenomenon is often referred to as vanishing gradient. Do you observe something like that in Net3?\n",
    "A: I observed that the training loss of Net3 decreases slowly, compared to previous nets.\n",
    "\n",
    "### 3. Compare the classification results by all three networks, which CNN do you think is the best performer?\n",
    "A: I think Net 1 performs better, because its diagonal elements of confusion matrix are larger.\n",
    "\n",
    "### 4. By observing your confusion matrices, which class or classes do you think are more difficult to correctly differentiate and why?\n",
    "A: I think it is \"pizza\". I am not sure if I make some mistakes in my Net, because my Nets predict most \"pizza\" images as \"dog\".\n",
    "\n",
    "### 5. What is one thing that you propose to make the classification performance better?\n",
    "A: Maybe we can use Skip Connections method to avoid the possible \"vanishing gradient\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b20140d5a202b5d660d65448b53023de7dbe126891fb42d4643a40fe5963133e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
